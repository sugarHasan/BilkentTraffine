{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML4RG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGhUQvdF4+7wviP6ue0wkw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarHasan/BilkentTraffine/blob/master/ML4RG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u48Dt4Ei43C3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from keras.models import Model, load_model, Sequential\n",
        "import keras.layers as kl\n",
        "import keras.optimizers as ko\n",
        "from keras.callbacks import EarlyStopping, History"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open('train_sequences.txt', 'r')\n",
        "file = file1.readlines()\n",
        "no_of_sequences = len(file)\n",
        "seq = list()\n",
        "labels = list()\n",
        "AA = {'A' , 'T' , 'G' , 'C' , 'N'}\n",
        "st = set()\n",
        "inf = set()\n",
        "for i in range(no_of_sequences):\n",
        "  str = \"\"\n",
        "  label = 0\n",
        "  for j in range(len(file[i])):\n",
        "    if((file[i][j] in AA) == False):\n",
        "      # print(file[i][j+1:])\n",
        "      label = float(file[i][j+1:])      \n",
        "      break;\n",
        "    str += file[i][j]\n",
        "  seq.append(str)  \n",
        "  st.add(len(str))\n",
        "  labels.append(label)\n",
        "# print(st)\n",
        "# for element in inf:\n",
        "#   print (element)\n",
        "maxL = max(st)\n",
        "sequences = np.zeros((no_of_sequences , maxL, 4))\n",
        "values = np.zeros(no_of_sequences)\n",
        "for i in range(no_of_sequences):\n",
        "  values[i] = labels[i]\n",
        "  temp = np.zeros((maxL, 4))\n",
        "  for j in range(len(seq[i])):\n",
        "    chr = seq[i][j]\n",
        "    # If you want - instead of random nucleotide, comment below if conditions\n",
        "    if(chr == 'N'):\n",
        "      chr = random.sample(set('ACGT'), 1)\n",
        "    if(chr=='A'):\n",
        "      temp[j][0] = 1\n",
        "    elif(chr == 'C'):\n",
        "      temp[j][1] = 1\n",
        "    elif(chr == 'G'):\n",
        "      temp[j][2] = 1\n",
        "    elif(chr == 'T'):\n",
        "      temp[j][3] = 1\n",
        "  # for j in range(len(seq[i]) , maxL):\n",
        "  #   temp[j]\n",
        "  sequences[i] = temp\n"
      ],
      "metadata": {
        "id": "aaEQKOGC5tfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFUi1Oms9WQU",
        "outputId": "543362d9-16c4-4d2a-c16a-f47b717dc07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114054, 137, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(st)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h30VRA1Y9YG5",
        "outputId": "b1d9bd8c-0fb2-453f-f8a0-5c12d3237a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{128, 129, 130, 132, 133, 134, 135, 136, 137, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should definitly do kind of an MSA appproach because dataset shape is not matching or can we split these data according to their sequence length buckets and use random forest algorithm? "
      ],
      "metadata": {
        "id": "h9eh-JyNXtuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This input is garbage and will change\n",
        "input = kl.Input(shape=(120,4))\n",
        "x = input\n",
        "x = kl.Conv1D(filters=32, kernel_size=12, activation=\"relu\")(x)\n",
        "x = kl.GlobalMaxPool1D()(x)\n",
        "x = kl.Flatten()(x)\n",
        "x = kl.Dense(12, activation=\"relu\")(x)\n",
        "# We need at least one dialated layer as well\n",
        "\n",
        "# Continuous variable hence linear activation?\n",
        "x = kl.Dense(1,activation=\"linear\")(x)"
      ],
      "metadata": {
        "id": "JL9F1cF5tNKd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}